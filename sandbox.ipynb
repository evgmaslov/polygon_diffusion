{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rplan validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rooms(rooms):\n",
    "    valid = True\n",
    "    if rooms == None:\n",
    "        valid = False\n",
    "    else:\n",
    "        for room in rooms:\n",
    "            mask = room[\"mask\"]\n",
    "            contours = mask_to_contour(mask, concat=False)\n",
    "            if len(contours) != 1:\n",
    "                valid = False\n",
    "                break\n",
    "    return valid\n",
    "\n",
    "def get_room_type(img_room_types, room_mask):\n",
    "    # return room type in the specified area ignoring doors\n",
    "    type_mask_inds = np.where((room_mask == 1) & (img_room_types != 15) & (img_room_types != 17))\n",
    "    room_type = list(set(img_room_types[type_mask_inds].flatten().tolist()))[0]\n",
    "    return room_type\n",
    "\n",
    "def get_room_mask(img_room_inds, ind):\n",
    "    # return room mask of ones\n",
    "    room_mask = np.where(img_room_inds==ind, np.ones_like(img_room_inds), np.zeros_like(img_room_inds)).astype(np.uint8)\n",
    "    return room_mask\n",
    "\n",
    "\n",
    "def mask_to_contour(mask, concat=True):\n",
    "    contours, _ = cv.findContours(mask.astype(np.uint8), cv.RETR_TREE, cv.CHAIN_APPROX_NONE)\n",
    "    contours = [contour.squeeze(1) for contour in contours]\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    if concat:\n",
    "        contours = np.concatenate(contours).T\n",
    "        # opencv coordinates to numpy indexes\n",
    "        contours[[0, 1]] = contours[[1, 0]]\n",
    "    else:\n",
    "        transformed_contours = []\n",
    "        for c in contours:\n",
    "            c = c.T\n",
    "            c[[0, 1]] = c[[1, 0]]\n",
    "            transformed_contours.append(c)\n",
    "        contours = transformed_contours\n",
    "    return contours\n",
    "\n",
    "def mask_to_corners(mask):\n",
    "    contours, _ = cv.findContours(mask.astype(np.uint8), cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    contours = [contour.squeeze(1) for contour in contours]\n",
    "    if len(contours) == 0:\n",
    "        return None\n",
    "    contours = np.concatenate(contours).T\n",
    "    # opencv coordinates to numpy indexes\n",
    "    contours[[0, 1]] = contours[[1, 0]]\n",
    "    return contours\n",
    "\n",
    "def mask_to_vertices(mask):\n",
    "    corner_points = mask_to_corners(mask)\n",
    "    if \"NoneType\" in str(type(corner_points)):\n",
    "        return None\n",
    "    corner_pairs = []\n",
    "    in_pairs = []\n",
    "    removes = np.ones(corner_points.shape[1])\n",
    "    for i in range(corner_points.shape[1]):\n",
    "        for j in range(i + 1, corner_points.shape[1]):\n",
    "            point1 = corner_points[:,i]\n",
    "            point2 = corner_points[:,j]\n",
    "            if abs(point1[0]-point2[0]) == 1 and abs(point1[1]-point2[1]) == 1:\n",
    "\n",
    "                sorted_points = [point1, point2] if point1[1] < point2[1] else [point2, point1]\n",
    "                sorted_inds = [i, j] if point1[1] < point2[1] else [j, i]\n",
    "                local_point1, local_point2 = sorted_points\n",
    "                ind1, ind2 = sorted_inds\n",
    "                if sorted_points[0][0] < sorted_points[1][0]:\n",
    "                    if mask[local_point1[0] + 1, local_point1[1]] == 0:\n",
    "                        if mask[local_point1[0], local_point1[1] - 1] == 0:\n",
    "                            removes[ind1] = 0\n",
    "                        if mask[local_point2[0] + 1, local_point2[1]] == 0:\n",
    "                            removes[ind2] = 0\n",
    "                    else:\n",
    "                        if mask[local_point2[0], local_point2[1] + 1] == 0:\n",
    "                            removes[ind2] = 0\n",
    "                        if mask[local_point1[0] - 1, local_point1[1]] == 0:\n",
    "                            removes[ind1] = 0\n",
    "                else:\n",
    "                    if mask[local_point1[0] - 1, local_point1[1]] == 0:\n",
    "                        if mask[local_point1[0], local_point1[1] - 1] == 0:\n",
    "                            removes[ind1] = 0\n",
    "                        if mask[local_point2[0] - 1, local_point2[1]] == 0:\n",
    "                            removes[ind2] = 0\n",
    "                    else:\n",
    "                        if mask[local_point2[0], local_point2[1] + 1] == 0:\n",
    "                            removes[ind2] = 0\n",
    "                        if mask[local_point1[0] + 1, local_point1[1]] == 0:\n",
    "                            removes[ind1] = 0\n",
    "\n",
    "                corner_pairs.append([point1, point2])\n",
    "                in_pairs.append(i)\n",
    "                in_pairs.append(j)\n",
    "    base_corners = []\n",
    "    for i in range(corner_points.shape[1]):\n",
    "        point = corner_points[:,i]\n",
    "        if i not in in_pairs or removes[i] == 0:\n",
    "            base_corners.append(np.expand_dims(point, axis=1))\n",
    "    base_corners = np.concatenate(base_corners, axis=1)\n",
    "    if len(corner_pairs) == 0:\n",
    "        return corner_points\n",
    "\n",
    "    merged_corners = []\n",
    "    for pair in corner_pairs:\n",
    "        point1 = pair[0]\n",
    "        point2 = pair[1]\n",
    "        min_a = min(point1[0], point2[0])\n",
    "        max_a = max(point1[0], point2[0])\n",
    "        min_b = min(point1[1], point2[1])\n",
    "        max_b = max(point1[1], point2[1])\n",
    "        candidates = None\n",
    "        if point1[0] == min_a and point1[1] == min_b or point1[0] == max_a and point1[1] == max_b:\n",
    "            candidates = [np.array([min_a, max_b]), np.array([max_a, min_b])]\n",
    "        elif point1[0] == min_a and point1[1] == max_b or point1[0] == max_a and point1[1] == min_b:\n",
    "            candidates = [np.array([min_a, min_b]), np.array([max_a, max_b])]\n",
    "        else:\n",
    "            return None\n",
    "        merged_point = None\n",
    "        if mask[candidates[0][0], candidates[0][1]] == 1:\n",
    "            merged_point = candidates[0]\n",
    "        elif mask[candidates[1][0], candidates[1][1]] == 1:\n",
    "            merged_point = candidates[1]\n",
    "        else:\n",
    "            return None\n",
    "        merged_point = np.expand_dims(merged_point, axis=1)\n",
    "        merged_corners.append(merged_point)\n",
    "    merged_corners = np.concatenate(merged_corners, axis=1)\n",
    "    vertices = np.concatenate([base_corners, merged_corners], axis=1)\n",
    "    return vertices\n",
    "\n",
    "def mask_to_lines(mask, vertices=False):\n",
    "    contour_points = mask_to_contour(mask)\n",
    "    corner_points = mask_to_vertices(mask) if vertices else mask_to_corners(mask)\n",
    "    if \"NoneType\" in str(type(contour_points)) or \"NoneType\" in str(type(corner_points)):\n",
    "        return None\n",
    "    lines = []\n",
    "    contour_points = contour_points.T\n",
    "    corner_points = corner_points.T\n",
    "    for i in range(len(corner_points)):\n",
    "        for j in range(i + 1, len(corner_points)):\n",
    "            left_point = corner_points[i]\n",
    "            right_point = corner_points[j]\n",
    "            # check if corners can be bounds of vertical or horizontal line because they have equal coordinate\n",
    "            if not (left_point[0] == right_point[0] or left_point[1] == right_point[1]):\n",
    "                continue\n",
    "\n",
    "            equal_ind = 0 if left_point[0] == right_point[0] else 1\n",
    "            boundary_ind = 0 if equal_ind == 1 else 1\n",
    "            min_boundary = left_point[boundary_ind] if left_point[boundary_ind] < right_point[boundary_ind] else right_point[boundary_ind]\n",
    "            max_boundary = left_point[boundary_ind] if left_point[boundary_ind] > right_point[boundary_ind] else right_point[boundary_ind]\n",
    "\n",
    "            # find contour points between corner points\n",
    "            eval_inds = np.where((contour_points[:,equal_ind] == left_point[equal_ind]) & (contour_points[:,boundary_ind] >= min_boundary) & (contour_points[:,boundary_ind] <= max_boundary))\n",
    "            # if there are no contour points between two corner points that means that this points are not bounds of contour line\n",
    "            if len(eval_inds[0]) < max_boundary - min_boundary - 1:\n",
    "                continue\n",
    "\n",
    "            line_inds = np.where((contour_points[:,equal_ind] == left_point[equal_ind]) & (contour_points[:,boundary_ind] > min_boundary) & (contour_points[:,boundary_ind] < max_boundary))\n",
    "            line_points = contour_points[line_inds[0]]\n",
    "            line_points = np.concatenate([np.expand_dims(left_point, axis=1), line_points.T, np.expand_dims(right_point, axis=1)], axis=1)\n",
    "\n",
    "            lines.append(line_points)\n",
    "    return lines\n",
    "\n",
    "def mask_to_polygon(mask):\n",
    "    contour_points = mask_to_contour(mask)\n",
    "    corner_points = mask_to_vertices(mask)\n",
    "    if \"NoneType\" in str(type(contour_points)) or \"NoneType\" in str(type(corner_points)):\n",
    "        return None\n",
    "\n",
    "    lines = mask_to_lines(mask, vertices=True)\n",
    "    polygon_graph = np.zeros((len(lines), len(lines)))\n",
    "    for i in range(len(lines)):\n",
    "        for j in range(i + 1, len(lines)):\n",
    "            line1 = lines[i]\n",
    "            line2 = lines[j]\n",
    "            corner_mask = np.zeros_like(mask)\n",
    "            corner_mask[line1[0], line1[1]] += 1\n",
    "            corner_mask[line2[0], line2[1]] += 1\n",
    "            corner = np.where(corner_mask == 2)\n",
    "            if len(corner[0]) > 0:\n",
    "                corner = np.array([corner[0][0], corner[1][0]])\n",
    "                intersections = np.where((corner_points[0,:] == corner[0]) & (corner_points[1,:] == corner[1]))[0]\n",
    "                if len(intersections) == 0:\n",
    "                    return None\n",
    "                corner_ind = intersections[0]\n",
    "                polygon_graph[i,j] = corner_ind + 1\n",
    "                polygon_graph[j,i] = corner_ind + 1\n",
    "\n",
    "    cons = get_connectivity_components(polygon_graph)\n",
    "    if len(cons) > 1:\n",
    "        return None\n",
    "    if len(lines) != len(corner_points[0]):\n",
    "        return None\n",
    "\n",
    "    # reconstruct polygon from graph\n",
    "    polygon_vertices = []\n",
    "    visited = np.zeros(len(lines))\n",
    "    cur_line = 0\n",
    "    while visited.sum() < len(lines):\n",
    "        neibs = np.where((polygon_graph[cur_line] != 0) & (visited == 0))[0].tolist()\n",
    "        if len(neibs) == 2:\n",
    "            first_vertex = int(polygon_graph[cur_line][neibs[0]] - 1)\n",
    "            next_vertex = int(polygon_graph[cur_line][neibs[1]] - 1)\n",
    "            polygon_vertices.append(np.expand_dims(corner_points[:,first_vertex], axis=1))\n",
    "            polygon_vertices.append(np.expand_dims(corner_points[:,next_vertex], axis=1))\n",
    "        elif len(neibs) == 1:\n",
    "            next_vertex = int(polygon_graph[cur_line][neibs[0]] - 1)\n",
    "            polygon_vertices.append(np.expand_dims(corner_points[:,next_vertex], axis=1))\n",
    "        visited[cur_line] = 1\n",
    "        if len(neibs) > 0:\n",
    "            cur_line = neibs[-1]\n",
    "    return polygon_vertices\n",
    "    \n",
    "def polygon_to_edges(vertices):\n",
    "    edges = [[vertices[i - 1], vertices[i]] for i in range(len(vertices))]\n",
    "    return edges\n",
    "\n",
    "def edge_to_line(edge):\n",
    "    equal_ind = 0 if edge[0][0] == edge[1][0] else 1\n",
    "    bound_ind = 0 if equal_ind == 1 else 1\n",
    "    left_ind = 0 if edge[0][bound_ind] > edge[1][bound_ind] else 1\n",
    "    right_ind = 0 if left_ind == 1 else 1\n",
    "    min_bound = int(edge[left_ind][bound_ind])\n",
    "    max_bound = int(edge[right_ind][bound_ind])\n",
    "    equal_bound = edge[0][equal_ind]\n",
    "    line = np.expand_dims(np.linspace(min_bound, max_bound, abs(max_bound - min_bound) + 1), axis=0).repeat(2, axis=0)\n",
    "    line[equal_ind, :] = equal_bound\n",
    "    return line.astype(np.int32)\n",
    "\n",
    "def line_to_edge(line):\n",
    "    equal_ind = 0 if line[0, 0] == line[0, 1] else 1\n",
    "    bound_ind = 0 if equal_ind == 1 else 1\n",
    "    equal_value = int(line[equal_ind, 0])\n",
    "    min_bound = int(line[bound_ind,:].min())\n",
    "    max_bound = int(line[bound_ind,:].max())\n",
    "    edge = [np.expand_dims([equal_value, min_bound], axis=1), np.expand_dims([equal_value, max_bound], axis=1)] if equal_ind == 0 else [np.expand_dims([min_bound, equal_value], axis=1), np.expand_dims([max_bound, equal_value], axis=1)]\n",
    "    return edge\n",
    "\n",
    "def polygon_to_mask(polygon):\n",
    "    img = Image.new('L', (256, 256), 0)\n",
    "    polygon = [(int(p[1]), int(p[0])) for p in polygon]\n",
    "    ImageDraw.Draw(img).polygon(polygon, outline=1, fill=1)\n",
    "    mask = np.array(img)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_points_bbox(points):\n",
    "    points_a = [p[0, 0].tolist() for p in points]\n",
    "    points_b = [p[1, 0].tolist() for p in points]\n",
    "    bbox = [min(points_a), min(points_b), max(points_a), max(points_b)]\n",
    "    return bbox\n",
    "\n",
    "def get_edge_bound(edge, axis):\n",
    "    first = edge[0][axis, 0].tolist()\n",
    "    second = edge[1][axis, 0].tolist()\n",
    "    bound = [min(first, second), max(first, second)]\n",
    "    return bound\n",
    "\n",
    "def get_bounds_intersection(bound1, bound2):\n",
    "    min_bound1 = bound1[0]\n",
    "    max_bound1 = bound1[1]\n",
    "    min_bound2 = bound2[0]\n",
    "    max_bound2 = bound2[1]\n",
    "\n",
    "    if max_bound1 <= min_bound2 or max_bound2 <= min_bound1:\n",
    "        return None\n",
    "    \n",
    "    intersection_bounds = []\n",
    "    if min_bound1 < min_bound2:\n",
    "        intersection_bounds.append(min_bound2)\n",
    "    else:\n",
    "        intersection_bounds.append(min_bound1)\n",
    "    if max_bound1 < max_bound2:\n",
    "        intersection_bounds.append(max_bound1)\n",
    "    else:\n",
    "        intersection_bounds.append(max_bound2)\n",
    "    return intersection_bounds\n",
    "\n",
    "def get_connectivity_components(graph):\n",
    "    is_visited = np.zeros(graph.shape[0])\n",
    "    stack = [0]\n",
    "    components = []\n",
    "    while is_visited.sum() < graph.shape[0]:\n",
    "        component = []\n",
    "        while len(stack) > 0:\n",
    "            cur = stack.pop()\n",
    "            is_visited[cur] = 1\n",
    "            component.append(cur)\n",
    "            neibs = np.where((graph[cur] != 0) & (is_visited == 0))[0].tolist()\n",
    "            stack.extend(neibs)\n",
    "        components.append(component)\n",
    "        not_visited = np.where(is_visited == 0)[0].tolist()\n",
    "        if len(not_visited) > 0:\n",
    "            stack.append(not_visited[0])\n",
    "    return components\n",
    "\n",
    "def fix_contour_holes(img_room_ind):\n",
    "    new_img_room_ind = img_room_ind.copy()\n",
    "    room_inds = list(set(img_room_ind.flatten().tolist()))\n",
    "    room_inds.remove(0)\n",
    "    for room_ind in room_inds:\n",
    "        mask = get_room_mask(img_room_ind, room_ind)\n",
    "        corners = mask_to_corners(mask)\n",
    "\n",
    "        holes = []\n",
    "        for i in range(corners.shape[1]):\n",
    "            c_i = corners[:, i]\n",
    "            for axis in [0, 1]:\n",
    "                for sign in [-1, 1]:\n",
    "                    tests = [mask[c_i[0] + sign * 1, c_i[1]], mask[c_i[0] + sign * 2, c_i[1]]] if axis == 0 else [mask[c_i[0], c_i[1] + sign * 1], mask[c_i[0], c_i[1] + sign * 2]]\n",
    "                    if tests[0] == 0 and tests[1] == 1:\n",
    "                        hole = [c_i[0] + sign, c_i[1]] if axis == 0 else [c_i[0], c_i[1] + sign]\n",
    "                        hole = np.array(hole)\n",
    "                        holes.append(np.expand_dims(hole, axis=1))\n",
    "        if len(holes) > 0:\n",
    "            holes = np.concatenate(holes, axis=1)\n",
    "            new_img_room_ind[*holes] = room_ind\n",
    "    return new_img_room_ind\n",
    "\n",
    "def get_rooms_without_spans(img):\n",
    "    img_room_type = img[:,:,1]\n",
    "    img_room_ind = fix_contour_holes(img[:,:,2])\n",
    "    room_inds = list(set(img_room_ind.flatten().tolist()))\n",
    "    room_inds.remove(0)\n",
    "\n",
    "    # get wall lines\n",
    "    wall_lines = []\n",
    "    wall_edges = []\n",
    "    edge_line_mapping = []\n",
    "    map_ind = 0\n",
    "    for ind in room_inds:\n",
    "        room_mask = get_room_mask(img_room_ind, ind)\n",
    "        room_polygon = mask_to_polygon(room_mask)\n",
    "        if room_polygon == None:\n",
    "            return None\n",
    "        room_edges = polygon_to_edges(room_polygon)\n",
    "        wall_edges.append(room_edges)\n",
    "        room_lines = [edge_to_line(e) for e in room_edges]\n",
    "        #room_lines = mask_to_lines(room_mask, vertices=True)\n",
    "        if \"NoneType\" in str(type(room_lines)):\n",
    "            return None\n",
    "        local_mapping = []\n",
    "        for line_points in room_lines:\n",
    "            line_dict = dict(\n",
    "                points = line_points,\n",
    "                room_ind = ind\n",
    "            )\n",
    "            wall_lines.append(line_dict)\n",
    "            local_mapping.append(map_ind)\n",
    "            map_ind += 1\n",
    "        edge_line_mapping.append(local_mapping)\n",
    "\n",
    "    # get vertical lines and horizontal lines\n",
    "    v_lines = []\n",
    "    h_lines = []\n",
    "    map_v = 0\n",
    "    map_h = 0\n",
    "    line_vh_mapping = []\n",
    "    for line in wall_lines:\n",
    "        line_points = line[\"points\"]\n",
    "        equal_ind = 0 if line_points[0][0] == line_points[0][1] else 1\n",
    "        if equal_ind == 0:\n",
    "            h_lines.append(line)\n",
    "            line_vh_mapping.append([1, map_h])\n",
    "            map_h += 1\n",
    "        else:\n",
    "            v_lines.append(line)\n",
    "            line_vh_mapping.append([0, map_v])\n",
    "            map_v += 1\n",
    "\n",
    "    # create move mask\n",
    "    move_masks = []\n",
    "    vh_moves = []\n",
    "    for lines in [v_lines, h_lines]:\n",
    "        equal_ind = 0 if lines[0][\"points\"][0][0] == lines[0][\"points\"][0][1] else 1\n",
    "        bound_ind = 0 if equal_ind == 1 else 1\n",
    "        graph = np.zeros((len(lines), len(lines)))\n",
    "        equal_values = []\n",
    "        for i in range(len(lines)):\n",
    "            line1 = lines[i]\n",
    "            line_points1 = line1[\"points\"]\n",
    "            equal_value1 = line_points1[equal_ind,0]\n",
    "            bounds1 = get_edge_bound(line_to_edge(line_points1), axis=bound_ind)\n",
    "\n",
    "            equal_values.append(equal_value1)\n",
    "            for j in range(i + 1, len(lines)):\n",
    "                line2 = lines[j]\n",
    "                line_points2 = line2[\"points\"]\n",
    "                equal_value2 = line_points2[equal_ind,0]\n",
    "                bounds2 = get_edge_bound(line_to_edge(line_points2), axis=bound_ind)\n",
    "\n",
    "                 # check that lines are edges of a wall\n",
    "                wall_spans = [{16}, {17}, {16, 17}]\n",
    "                wall_bound = False\n",
    "                bounds_intersection = get_bounds_intersection(bounds1, bounds2)\n",
    "                if bounds_intersection != None:\n",
    "                    min_bound, max_bound = bounds_intersection\n",
    "                    min_equal = min(equal_value1, equal_value2)\n",
    "                    max_equal = max(equal_value1, equal_value2)\n",
    "\n",
    "                    # +1 to ensure bounds are not in span itself\n",
    "                    eval_bounds = [min_equal+1, max_equal, min_bound+1, max_bound] if equal_ind == 0 else [min_bound+1, max_bound, min_equal+1, max_equal]\n",
    "\n",
    "                    type_span = img_room_type[eval_bounds[0]:eval_bounds[1], eval_bounds[2]:eval_bounds[3]]\n",
    "                    # +-2 in bound ind to validate that bound index isn't blocked with other rooms\n",
    "                    ind_span = img_room_ind[eval_bounds[0]:eval_bounds[1], eval_bounds[2]-2:eval_bounds[3]+2] if equal_ind == 0 else img_room_ind[eval_bounds[0]-2:eval_bounds[1]+2, eval_bounds[2]:eval_bounds[3]]\n",
    "                    \n",
    "                    span_types = set(type_span.flatten().tolist())\n",
    "                    span_inds = set(ind_span.flatten().tolist())\n",
    "\n",
    "                    # check if lines are short edges of the room\n",
    "                    short_edges = False\n",
    "                    short_ind_span1 = img_room_ind[min_equal+1: max_equal, min_bound: min_bound + 1] if equal_ind == 0 else img_room_ind[min_bound: min_bound + 1, min_equal+1: max_equal]\n",
    "                    short_ind_span2 = img_room_ind[min_equal+1: max_equal, max_bound: max_bound + 1] if equal_ind == 0 else img_room_ind[max_bound: max_bound + 1, min_equal+1: max_equal]\n",
    "                    short_type_span1 = img_room_type[min_equal+1: max_equal, min_bound: min_bound + 1] if equal_ind == 0 else img_room_type[min_bound: min_bound + 1, min_equal+1: max_equal]\n",
    "                    short_type_span2 = img_room_type[min_equal+1: max_equal, max_bound: max_bound + 1] if equal_ind == 0 else img_room_type[max_bound: max_bound + 1, min_equal+1: max_equal]\n",
    "                    short_ind_set1 = set(short_ind_span1.flatten().tolist())\n",
    "                    short_ind_set2 = set(short_ind_span2.flatten().tolist())\n",
    "                    short_type_set1 = set(short_type_span1.flatten().tolist())\n",
    "                    short_type_set2 = set(short_type_span2.flatten().tolist())\n",
    "                    if line1[\"room_ind\"] == line2[\"room_ind\"]:\n",
    "                        if short_ind_set1 == {line1[\"room_ind\"]} and short_type_set2 in wall_spans or short_ind_set2 == {line1[\"room_ind\"]} and short_type_set1 in wall_spans:\n",
    "                            short_edges = True\n",
    "\n",
    "                    # check if span only contains interior walls and doors\n",
    "                    if span_types in wall_spans and span_inds == {0} or short_edges:\n",
    "                        wall_bound = True\n",
    "\n",
    "                if wall_bound or equal_value1 == equal_value2:\n",
    "                    graph[i,j] = 1\n",
    "                    graph[j,i] = 1\n",
    "        components = get_connectivity_components(graph)\n",
    "        \n",
    "        moves = np.zeros(len(lines))\n",
    "        for component in components:\n",
    "            base_value = equal_values[component[0]]\n",
    "            moves[component[0]] = 0\n",
    "            for i in range(1, len(component)):\n",
    "                move = base_value - equal_values[component[i]]\n",
    "                moves[component[i]] = move\n",
    "        move_mask = np.zeros((256, 256))\n",
    "        for i in range(len(lines)):\n",
    "            line = lines[i]\n",
    "            line_points = line[\"points\"]\n",
    "            move = moves.tolist()[i]\n",
    "            move_mask[*line_points] = move\n",
    "        move_masks.append(move_mask)\n",
    "        vh_moves.append(moves)\n",
    "    \n",
    "    rooms = []\n",
    "    for i, ind in enumerate(room_inds):\n",
    "        edges = wall_edges[i]\n",
    "        mask = get_room_mask(img_room_ind, ind)\n",
    "        room_type = get_room_type(img_room_type, mask)\n",
    "        new_polygon = [e[1].copy() for e in edges]\n",
    "        for j, edge in enumerate(edges):\n",
    "            equal_ind = 0 if edge[0][0] == edge[1][0] else 1\n",
    "            bound_ind = 0 if equal_ind == 1 else 1\n",
    "            move_map = line_vh_mapping[edge_line_mapping[i][j]]\n",
    "            move = int(vh_moves[move_map[0]][move_map[1]].tolist())\n",
    "            new_polygon[j - 1][equal_ind, :] += move\n",
    "            new_polygon[j][equal_ind, :] += move\n",
    "        new_mask = polygon_to_mask(new_polygon)\n",
    "        room = dict(\n",
    "            mask = new_mask,\n",
    "            type = room_type\n",
    "        )\n",
    "        rooms.append(room)\n",
    "    return rooms\n",
    "\n",
    "\n",
    "    # move room borders and create room dicts\n",
    "    rooms = []\n",
    "    for ind in room_inds:\n",
    "        mask = get_room_mask(img_room_ind, ind)\n",
    "        room_type = get_room_type(img_room_type, mask)\n",
    "        room_lines = mask_to_lines(mask, vertices=True)\n",
    "        if \"NoneType\" in str(type(room_lines)):\n",
    "            return None\n",
    "        lines_blocked = 0\n",
    "        while lines_blocked < len(room_lines):\n",
    "            i = 0\n",
    "            while i < len(room_lines):\n",
    "                line = room_lines[i]\n",
    "                equal_ind = 0 if line[0][0] == line[0][1] else 1\n",
    "                bound_ind = 0 if equal_ind == 1 else 1\n",
    "                equal_value = line[equal_ind, 0]\n",
    "                min_bound = line[bound_ind].min()\n",
    "                max_bound = line[bound_ind].max()\n",
    "                move_mask = move_masks[1] if equal_ind == 0 else move_masks[0]\n",
    "\n",
    "                move_values = list(set(move_mask[*line].flatten().tolist()))\n",
    "                if 0 in move_values:\n",
    "                    move_values.remove(0)\n",
    "                if len(move_values) == 0:\n",
    "                    lines_blocked += 1\n",
    "                    i += 1\n",
    "                    continue\n",
    "                \n",
    "                move = move_values[0]\n",
    "                new_equal_value = equal_value + int(move)\n",
    "                min_equal_value = equal_value if equal_value < new_equal_value else new_equal_value\n",
    "                max_equal_value = equal_value if equal_value > new_equal_value else new_equal_value\n",
    "                \n",
    "\n",
    "                if equal_ind == 0:\n",
    "                    indicators = set(mask[min_equal_value:max_equal_value+1, min_bound:max_bound+1].flatten().tolist())\n",
    "                    if 0 in indicators or abs(min_bound - max_bound) == 1:\n",
    "                        mask[min_equal_value:max_equal_value+1, min_bound:max_bound+1] = 1\n",
    "                    else:\n",
    "                        mask[min_equal_value:max_equal_value+1, min_bound:max_bound+1] = 0\n",
    "                else:\n",
    "                    indicators = set(mask[min_bound:max_bound+1, min_equal_value:max_equal_value+1].flatten().tolist())\n",
    "                    if 0 in indicators or abs(min_bound - max_bound) == 1:\n",
    "                        mask[min_bound:max_bound+1, min_equal_value:max_equal_value+1] = 1\n",
    "                    else:\n",
    "                        mask[min_bound:max_bound+1, min_equal_value:max_equal_value+1] = 0\n",
    "                \n",
    "                room_lines = mask_to_lines(mask, vertices=True)\n",
    "                if \"NoneType\" in str(type(room_lines)):\n",
    "                    return None\n",
    "\n",
    "                lines_blocked = 0\n",
    "                i += 1\n",
    "        room_dict = dict(\n",
    "            mask = mask,\n",
    "            type = room_type\n",
    "        )\n",
    "        rooms.append(room_dict)\n",
    "    return rooms\n",
    "\n",
    "def get_rooms_graph(base_img, unspaned_masks):\n",
    "    img_room_type = base_img[:,:,1]\n",
    "    img_room_ind = base_img[:,:,2]\n",
    "    room_inds = list(set(img_room_ind.flatten().tolist()))\n",
    "    room_inds.remove(0)\n",
    "\n",
    "    rooms_graph = np.zeros((len(room_inds), len(room_inds)))\n",
    "    for i in range(len(room_inds)):\n",
    "        ind1 = room_inds[i]\n",
    "        mask1 = get_room_mask(img_room_ind, ind1)\n",
    "        unspaned_mask1 = unspaned_masks[ind1 - 1]\n",
    "        lines1 = mask_to_lines(mask1)\n",
    "        edges1 = [line_to_edge(l) for l in lines1]\n",
    "\n",
    "        for j in range(i + 1, len(room_inds)):\n",
    "            connected = False\n",
    "            ind2 = room_inds[j]\n",
    "            mask2 = get_room_mask(img_room_ind, ind2)\n",
    "            unspaned_mask2 = unspaned_masks[ind2 - 1]\n",
    "            lines2 = mask_to_lines(mask2)\n",
    "            edges2 = [line_to_edge(l) for l in lines2]\n",
    "\n",
    "            con_mask = np.zeros_like(unspaned_mask1)\n",
    "            con_mask[np.where(unspaned_mask1 == 1)] += 1\n",
    "            con_mask[np.where(unspaned_mask2 == 1)] += 1\n",
    "            if len(np.where(con_mask == 2)[0]) == 0:\n",
    "                #print(ind1, ind2)\n",
    "                #display(Image.fromarray(50*con_mask.astype(np.uint8)))\n",
    "                continue\n",
    "            \n",
    "            for e1 in edges1:\n",
    "                equal_ind1 = 0 if e1[0][0] == e1[1][0] else 1\n",
    "                bound_ind1 = 0 if equal_ind1 == 1 else 1\n",
    "                equal_value1 = e1[0][equal_ind1].tolist()[0]\n",
    "                bound1 = get_edge_bound(e1, axis=bound_ind1)\n",
    "\n",
    "                has_door = False\n",
    "                for e2 in edges2:\n",
    "                    equal_ind2 = 0 if e2[0][0] == e2[1][0] else 1\n",
    "                    bound_ind2 = 0 if equal_ind2 == 1 else 1\n",
    "                    equal_value2 = e2[0][equal_ind2].tolist()[0]\n",
    "                    bound2 = get_edge_bound(e2, axis=bound_ind2)\n",
    "\n",
    "                    if equal_ind1 != equal_ind2:\n",
    "                        continue\n",
    "\n",
    "                    # check that there are a door between lines\n",
    "                    bounds_intersection = get_bounds_intersection(bound1, bound2)\n",
    "                    if bounds_intersection != None:\n",
    "                        min_bound, max_bound = bounds_intersection\n",
    "                        min_equal = min(equal_value1, equal_value2)\n",
    "                        max_equal = max(equal_value1, equal_value2)\n",
    "\n",
    "                        # +1 to ensure bounds are not in span itself\n",
    "                        med_equal = int((min_equal + max_equal) / 2)\n",
    "                        eval_bounds = [med_equal, med_equal+1, min_bound+1, max_bound] if equal_ind1 == 0 else [min_bound+1, max_bound, med_equal, med_equal+1]\n",
    "                        type_span = img_room_type[eval_bounds[0]:eval_bounds[1], eval_bounds[2]:eval_bounds[3]]\n",
    "                        ind_span = img_room_ind[eval_bounds[0]:eval_bounds[1], eval_bounds[2]:eval_bounds[3]]\n",
    "                        \n",
    "                        span_types = set(type_span.flatten().tolist())\n",
    "                        span_inds = set(ind_span.flatten().tolist())\n",
    "                        # check if span only contains interior walls and doors\n",
    "                        door_spans = [{17}, {16, 17}]\n",
    "                        #print(span_types, ind1, ind2)\n",
    "                        if span_types in door_spans and span_inds == {0}:\n",
    "                            has_door = True\n",
    "                if has_door:\n",
    "                    connected = True\n",
    "                    break\n",
    "            if connected:\n",
    "                rooms_graph[ind1 - 1, ind2 - 1] = 1\n",
    "                rooms_graph[ind2 - 1, ind1 - 1] = 1\n",
    "    return rooms_graph\n",
    "\n",
    "def get_corruption_boundaries(polygon):\n",
    "    mask = polygon_to_mask(polygon)\n",
    "    bounds = []\n",
    "    edges = polygon_to_edges(polygon)\n",
    "    for e in edges:\n",
    "        equal_ind = 0 if e[0][0] == e[1][0] else 1\n",
    "        bound_ind = 0 if equal_ind == 1 else 1\n",
    "        first_bound, second_bound = get_edge_bound(e, axis=bound_ind)\n",
    "        equal_value = e[0][equal_ind].tolist()[0]\n",
    "\n",
    "        distances = []\n",
    "        for bound in [first_bound, first_bound + 1, max(first_bound - 1, 0), second_bound, second_bound - 1, min(second_bound + 1, 255)]:\n",
    "            left_range = [bound, bound+1, 0, equal_value] if bound_ind == 0 else [0, equal_value, bound, bound+1]\n",
    "            right_equal_value = equal_value + 1 if equal_value < 255 else equal_value\n",
    "            right_range = [bound, bound+1, right_equal_value, 256] if bound_ind == 0 else [right_equal_value, 256, bound, bound+1]\n",
    "            left_equal_value = equal_value - 1 if equal_value > 0 else equal_value\n",
    "            get_left_distances = lambda x: left_equal_value - np.where(mask[left_range[0]:left_range[1],left_range[2]:left_range[3]] == x)[equal_ind]\n",
    "            get_right_distances = lambda x: np.where(mask[right_range[0]:right_range[1],right_range[2]:right_range[3]] == x)[equal_ind]\n",
    "            max_left_dist = equal_value\n",
    "            max_right_dist = 255 - equal_value\n",
    "            for dist in [[max_left_dist, get_left_distances], [max_right_dist, get_right_distances]]:\n",
    "                dist_border, dist_func = dist\n",
    "                min_empty = abs(dist_func(0)).min().tolist() if len(dist_func(0)) > 0 else 0\n",
    "                min_room = abs(dist_func(1)).min().tolist() if len(dist_func(1)) > 0 else dist_border\n",
    "                max_empty = abs(dist_func(0)).max().tolist() if len(dist_func(0)) > 0 else 0\n",
    "                max_room = abs(dist_func(1)).max().tolist() if len(dist_func(1)) > 0 else dist_border\n",
    "                distances.extend([min_empty, min_room, max_empty, max_room])\n",
    "        \n",
    "        left_candidates = []\n",
    "        left_min_emptys = [0, 8, 16, 24, 32, 40]\n",
    "        left_min_rooms = [1, 9, 17, 25, 33, 41]\n",
    "        for i, j in zip(left_min_emptys, left_min_rooms):\n",
    "            candidate = max(distances[i] - 3, 0) if distances[i] > 0 else max(distances[j] - 3, 0)\n",
    "            left_candidates.append(candidate)\n",
    "        left_limit = min(left_candidates)\n",
    "        right_candidates = []\n",
    "        right_min_emptys = [4, 12, 20, 28, 36, 44]\n",
    "        right_min_rooms = [5, 13, 21, 29, 37, 45]\n",
    "        for i, j in zip(right_min_emptys, right_min_rooms):\n",
    "            candidate = max(distances[i] - 3, 0) if distances[i] > 0 else max(distances[j] - 3, 0)\n",
    "            right_candidates.append(candidate)\n",
    "        right_limit = min(right_candidates)\n",
    "        bounds.append([left_limit, right_limit])\n",
    "    return bounds\n",
    "\n",
    "def edge_corrupt(polygons, cor_ind, pair_ind):\n",
    "    polygon1 = polygons[cor_ind]\n",
    "    polygon1 = [p.copy() for p in polygon1]\n",
    "    polygon2 = polygons[pair_ind]\n",
    "    polygon2 = [p.copy() for p in polygon2]\n",
    "    mask2 = polygon_to_mask(polygon2)\n",
    "    corruption_limits = get_corruption_boundaries(polygon1)\n",
    "\n",
    "    edges1 = polygon_to_edges(polygon1)\n",
    "    polygon_candidates = []\n",
    "    for moving_edge_ind in range(len(edges1)):\n",
    "        local_polygon = [p.copy() for p in polygon1]\n",
    "        moving_edge = edges1[moving_edge_ind]\n",
    "        moving_equal_ind = 0 if moving_edge[0][0] == moving_edge[1][0] else 1\n",
    "        moving_equal_value = moving_edge[0][moving_equal_ind, 0].tolist()\n",
    "        moving_bound_ind = 0 if moving_equal_ind == 1 else 1\n",
    "        moving_edge_bound = get_edge_bound(moving_edge, moving_bound_ind)\n",
    "        edge_corruption_limits = corruption_limits[moving_edge_ind]\n",
    "        corruption_bound = [moving_equal_value - edge_corruption_limits[0], moving_equal_value + edge_corruption_limits[1]]\n",
    "        eval_bound = [*moving_edge_bound, *corruption_bound] if moving_equal_ind == 1 else [*corruption_bound, *moving_edge_bound]\n",
    "\n",
    "        eval_mask = mask2.copy()\n",
    "        eval_mask[eval_bound[0] + 1:eval_bound[1], eval_bound[2] + 1: eval_bound[3]] += 1\n",
    "        candidate_inds = np.where(eval_mask == 2)\n",
    "        if len(candidate_inds[0]) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if candidate_inds[moving_equal_ind].max() == candidate_inds[moving_equal_ind].min():\n",
    "                continue\n",
    "        candidate_inds = candidate_inds[moving_equal_ind].tolist()\n",
    "        new_equal_value = random.sample(candidate_inds, 1)\n",
    "        local_polygon[moving_edge_ind - 1][moving_equal_ind, :] = new_equal_value\n",
    "        local_polygon[moving_edge_ind][moving_equal_ind, :] = new_equal_value\n",
    "        polygon_candidates.append(local_polygon)\n",
    "    if len(polygon_candidates) == 0:\n",
    "        return None\n",
    "    polygon1 = random.sample(polygon_candidates, 1)[0]\n",
    "\n",
    "    return polygon1\n",
    "\n",
    "def move_corrupt(polygons, cor_ind, pair_ind):\n",
    "    polygon1 = polygons[cor_ind]\n",
    "    polygon1 = [v.copy() for v in polygon1]\n",
    "    polygon2 = polygons[pair_ind]\n",
    "    polygon2 = [v.copy() for v in polygon2]\n",
    "    mask2 = polygon_to_mask(polygon2)\n",
    "\n",
    "    inner_points = np.where(mask2 == 1)\n",
    "    inner_points = np.concatenate([np.expand_dims(coord, axis=0) for coord in inner_points], axis=0)\n",
    "\n",
    "    polygon_bbox = get_points_bbox(polygon1)\n",
    "\n",
    "    pairs_to_move = []\n",
    "    all_bounds = []\n",
    "    for i in range(len(polygon1)):\n",
    "        v = polygon1[i]\n",
    "        broadcasted_v = np.repeat(v, inner_points.shape[1], axis=1)\n",
    "        distances = inner_points - broadcasted_v\n",
    "        signs = np.sign(distances)\n",
    "        bounds = [polygon_bbox[0] - v[0, 0].tolist(), polygon_bbox[1] - v[1, 0].tolist(), polygon_bbox[2] - v[0, 0].tolist(), polygon_bbox[3] - v[1, 0].tolist()]\n",
    "        all_bounds.append(bounds)\n",
    "        valid_points = np.where((signs[0,:] != 0) & (signs[1,:] != 0) & (inner_points[0,:] + bounds[0] >= 0) & (inner_points[0,:] + bounds[2] <= 255) & (inner_points[1,:] + bounds[1] >= 0) & (inner_points[1,:] + bounds[3] <= 255))\n",
    "        if len(valid_points[0]) > 0:\n",
    "            pairs_to_move.append([i, valid_points[0]])\n",
    "    if len(pairs_to_move) == 0:\n",
    "        return None\n",
    "    pair = random.sample(pairs_to_move, 1)[0]\n",
    "    point_ind = random.sample(pair[1].tolist(), 1)[0]\n",
    "    point_to_move = polygon1[pair[0]]\n",
    "    base_point = np.expand_dims(inner_points[:, point_ind], axis=1)\n",
    "    vec = base_point - point_to_move\n",
    "    corrupted_polygon = [v + vec for v in polygon1]\n",
    "    return corrupted_polygon\n",
    "\n",
    "def neib_corrupt(polygons, cor_ind, pair_ind):\n",
    "    rest_polygons = [polygons[i] for i in range(len(polygons)) if i != cor_ind]\n",
    "    cor_polygon = polygons[cor_ind]\n",
    "    pair_polygon = polygons[pair_ind]\n",
    "    pair_mask = polygon_to_mask(pair_polygon)\n",
    "\n",
    "    cor_bbox = get_points_bbox(cor_polygon)\n",
    "    rest_bbox = get_points_bbox([point for polygon in rest_polygons for point in polygon])\n",
    "    rest_mask = np.zeros_like(pair_mask)\n",
    "    for p in rest_polygons:\n",
    "        local_mask = polygon_to_mask(p)\n",
    "        rest_mask = np.where(local_mask == 1, np.ones_like(local_mask), rest_mask)\n",
    "\n",
    "    cor_edges = polygon_to_edges(cor_polygon)\n",
    "    cor_bbox_edges = []\n",
    "    for i in range(len(cor_edges)):\n",
    "        edge = cor_edges[i]\n",
    "        equal_ind = 0 if edge[0][0] == edge[1][0] else 1\n",
    "        bound_ind = 0 if equal_ind == 1 else 1\n",
    "        equal_value = edge[0][equal_ind, 0].tolist()\n",
    "        min_bound, max_bound = get_edge_bound(edge, axis=bound_ind)\n",
    "\n",
    "        sign = None\n",
    "        space = None\n",
    "        bbox_bound = None\n",
    "        if equal_value == cor_bbox[0] and equal_ind == 0:\n",
    "            sign = -1\n",
    "            space = abs(cor_bbox[0] - cor_bbox[2])\n",
    "            bbox_bound = [cor_bbox[1], cor_bbox[3]]\n",
    "        elif equal_value == cor_bbox[1] and equal_ind == 1:\n",
    "            sign = -1\n",
    "            space = abs(cor_bbox[1] - cor_bbox[3])\n",
    "            bbox_bound = [cor_bbox[0], cor_bbox[2]]\n",
    "        elif equal_value == cor_bbox[2] and equal_ind == 0:\n",
    "            sign = 1\n",
    "            space = abs(cor_bbox[0] - cor_bbox[2])\n",
    "            bbox_bound = [cor_bbox[1], cor_bbox[3]]\n",
    "        elif equal_value == cor_bbox[3] and equal_ind == 1:\n",
    "            sign = 1\n",
    "            space = abs(cor_bbox[1] - cor_bbox[3])\n",
    "            bbox_bound = [cor_bbox[0], cor_bbox[2]]\n",
    "        else:\n",
    "            continue\n",
    "        length = abs(min_bound - max_bound) + 1\n",
    "        left_limit = abs(min_bound - bbox_bound[0])\n",
    "        right_limit = abs(max_bound - bbox_bound[1])\n",
    "\n",
    "        edge_info = [i, equal_ind, equal_value, min_bound, max_bound, sign, space, length, left_limit, right_limit]\n",
    "        cor_bbox_edges.append(edge_info)\n",
    "    \n",
    "    rest_edges = [edge for polygon in rest_polygons for edge in polygon_to_edges(polygon)]\n",
    "    rest_bbox_edges = []\n",
    "    for i in range(len(rest_edges)):\n",
    "        edge = rest_edges[i]\n",
    "        equal_ind = 0 if edge[0][0] == edge[1][0] else 1\n",
    "        bound_ind = 0 if equal_ind == 1 else 1\n",
    "        equal_value = edge[0][equal_ind, 0].tolist()\n",
    "        min_bound, max_bound = get_edge_bound(edge, axis=bound_ind)\n",
    "\n",
    "        sign = None\n",
    "        space = None\n",
    "        if equal_value == rest_bbox[0] and equal_ind == 0:\n",
    "            sign = -1\n",
    "            space = rest_bbox[0] - 1\n",
    "        elif equal_value == rest_bbox[1] and equal_ind == 1:\n",
    "            sign = -1\n",
    "            space = rest_bbox[1] - 1\n",
    "        elif equal_value == rest_bbox[2] and equal_ind == 0:\n",
    "            sign = 1\n",
    "            space = 255 - rest_bbox[2]\n",
    "        elif equal_value == rest_bbox[3] and equal_ind == 1:\n",
    "            sign = 1\n",
    "            space = 255 - rest_bbox[2]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        edge_info = [i, equal_ind, equal_value, min_bound, max_bound, sign, space]\n",
    "        rest_bbox_edges.append(edge_info)\n",
    "    \n",
    "    valid_dir_vecs = []\n",
    "    for edge_info1 in cor_bbox_edges:\n",
    "        for edge_info2 in rest_bbox_edges:\n",
    "            if edge_info1[1] != edge_info2[1] or edge_info1[5] == edge_info2[5] or edge_info1[6] > edge_info2[6]:\n",
    "                continue\n",
    "            bound_ind = 0 if edge_info1[1] == 1 else 0\n",
    "            edge1 = cor_edges[edge_info1[0]]\n",
    "            sorted_edge1 = edge1 if edge1[0][bound_ind, 0] < edge1[1][bound_ind, 0] else [edge1[1], edge1[0]]\n",
    "            edge2 = rest_edges[edge_info2[0]]\n",
    "            sorted_edge2 = edge2 if edge2[0][bound_ind, 0] < edge2[1][bound_ind, 0] else [edge2[1], edge2[0]]\n",
    "            vec_candidates = []\n",
    "            if edge_info2[3] - edge_info1[7] + 1 - edge_info1[8] >= 0 and edge_info2[3] + edge_info1[9] <= 255:\n",
    "                vec = sorted_edge2[0] - sorted_edge1[1]\n",
    "                if vec[0, 0] != 0 and vec[1, 0] != 0:\n",
    "                    vec_candidates.append(vec)\n",
    "            elif edge_info2[3] - edge_info1[8] >= 0 and edge_info2[3] + edge_info1[7] - 1 + edge_info1[9] <= 255:\n",
    "                vec = sorted_edge2[0] - sorted_edge1[0]\n",
    "                if vec[0, 0] != 0 and vec[1, 0] != 0:\n",
    "                    vec_candidates.append(vec)\n",
    "            elif edge_info2[4] - edge_info1[7] + 1 - edge_info1[8] >= 0 and edge_info2[4] + edge_info1[9] <= 255:\n",
    "                vec = sorted_edge2[1] - sorted_edge1[1]\n",
    "                if vec[0, 0] != 0 and vec[1, 0] != 0:\n",
    "                    vec_candidates.append(vec)\n",
    "            elif edge_info2[4] - edge_info1[8] >= 0 and edge_info2[4] + edge_info1[7] - 1 + edge_info1[9] <= 255:\n",
    "                vec = sorted_edge2[1] - sorted_edge1[0]\n",
    "                if vec[0, 0] != 0 and vec[1, 0] != 0:\n",
    "                    vec_candidates.append(vec)\n",
    "            else:\n",
    "                continue\n",
    "            for v in vec_candidates:\n",
    "                test_edge = [p.copy() for p in edge1]\n",
    "                test_line = edge_to_line(test_edge)\n",
    "                test_line += np.repeat(v, test_line.shape[1], axis=1)\n",
    "                if len(np.where(pair_mask[*test_line] == 1)[0]) == 0 and len(np.where(rest_mask[*test_line] == 1)[0]) > 1:\n",
    "                    valid_dir_vecs.append(v)\n",
    "    if len(valid_dir_vecs) == 0:\n",
    "        return None\n",
    "    \n",
    "    vec = random.sample(valid_dir_vecs, 1)[0]\n",
    "    new_polygon = [p.copy() for p in cor_polygon]\n",
    "    new_polygon = [p + vec for p in new_polygon] \n",
    "    return new_polygon\n",
    "\n",
    "def get_corruption_pairs_sequences(n_polygons):\n",
    "    replacements = [[i] for i in range(n_polygons)]\n",
    "    for i in range(n_polygons - 1):\n",
    "        new_replacements = []\n",
    "        for r in replacements:\n",
    "            for j in range(n_polygons):\n",
    "                if j not in r:\n",
    "                    new_replacements.append(r + [j])\n",
    "        replacements.extend(new_replacements)\n",
    "    sequences = []\n",
    "    for r in replacements:\n",
    "        n_pairs = int(len(r) / 2)\n",
    "        sequence = [[r[2*i], r[2*i + 1]] for i in range(n_pairs)]\n",
    "        if len(sequence) > 0:\n",
    "            sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "def get_corrupt_sequences(n_polygons, max_n_seq=-1):\n",
    "    sequences = get_corruption_pairs_sequences(n_polygons)\n",
    "    corrupts = []\n",
    "    funcs = [edge_corrupt, move_corrupt, neib_corrupt]\n",
    "    seq_lens = list(set([len(s) for s in sequences]))\n",
    "    lens_func_inds = {}\n",
    "    for l in seq_lens:\n",
    "        func_inds = [[0 for _ in range(l)]]\n",
    "        for i in range(l - 1, -1, -1):\n",
    "            local_inds = []\n",
    "            for j in range(len(funcs)):\n",
    "                for inds in func_inds:\n",
    "                    new_inds = inds.copy()\n",
    "                    if new_inds[i] != j:\n",
    "                        new_inds[i] = j\n",
    "                        local_inds.append(new_inds)\n",
    "            func_inds.extend(local_inds)\n",
    "        lens_func_inds[l] = func_inds\n",
    "    if max_n_seq > 0:\n",
    "        sequences = random.sample(sequences, min(max_n_seq, len(sequences)))\n",
    "    for s in tqdm(sequences, desc=f\"Creating corruption sequences for {n_polygons}\"):\n",
    "        func_inds = lens_func_inds[len(s)]\n",
    "\n",
    "        local_corrupts = []\n",
    "        for i in range(len(func_inds)):\n",
    "            cor = []\n",
    "            for j in range(len(s)):\n",
    "                cor.append([func_inds[i][j], s[j]])\n",
    "            local_corrupts.append(cor)\n",
    "        corrupts.extend(local_corrupts)\n",
    "    return corrupts\n",
    "\n",
    "def corrupt(polygons, connections_graph, corrupt_sequences, return_seq=False):\n",
    "    polygons = [[v.copy() for v in p] for p in polygons]\n",
    "    corrupts = [seq.copy() for seq in corrupt_sequences]\n",
    "    funcs = [edge_corrupt, move_corrupt, neib_corrupt]\n",
    "    \n",
    "    corrupted = None\n",
    "    cor_seq = None\n",
    "    n_errors = 0\n",
    "    max_n_errors = 10\n",
    "    while corrupted == None:\n",
    "        corrupt_ind = random.sample(range(len(corrupts)), 1)[0]\n",
    "        corrupt_seq = corrupts[corrupt_ind]\n",
    "        eval_seq = []\n",
    "        for cor in corrupt_seq:\n",
    "            pair = cor[1]\n",
    "            if cor[0] != 2 or pair[1] in np.where(connections_graph[pair[0]] == 1)[0]:\n",
    "                eval_seq.append(cor)\n",
    "        if len(eval_seq) != len(corrupt_seq):\n",
    "            corrupts.pop(corrupt_ind)\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            local_corrupt = polygons\n",
    "            for cor in corrupt_seq:\n",
    "                if local_corrupt != None:\n",
    "                    cor_polygon = funcs[cor[0]](local_corrupt, cor[1][0], cor[1][1])\n",
    "                    if cor_polygon == None:\n",
    "                        local_corrupt = None\n",
    "                    else:\n",
    "                        local_corrupt[cor[1][0]] = cor_polygon\n",
    "        except Exception as error:\n",
    "            corrupts.pop(corrupt_ind)\n",
    "            n_errors += 1\n",
    "            if n_errors > max_n_errors:\n",
    "                raise error\n",
    "            continue\n",
    "                    \n",
    "        corrupted = local_corrupt\n",
    "        cor_seq = corrupt_seq\n",
    "        corrupts.pop(corrupt_ind)\n",
    "    output = (corrupted, cor_seq) if return_seq else corrupted\n",
    "    return output\n",
    "\n",
    "def get_polygon_area(polygon):\n",
    "    mask = polygon_to_mask(polygon)\n",
    "    area = len(np.where(mask == 1)[0])\n",
    "    return area\n",
    "\n",
    "def rplan_img_to_dict(img):\n",
    "    rooms = get_rooms_without_spans(img)\n",
    "    if not check_rooms(rooms):\n",
    "        return None\n",
    "    masks = [room[\"mask\"] for room in rooms]\n",
    "    rooms_graph = get_rooms_graph(img, masks)\n",
    "    json_dict = dict(\n",
    "        rooms = [],\n",
    "        graph = rooms_graph.astype(np.int32).tolist()\n",
    "    )\n",
    "    for i in range(len(rooms)):\n",
    "        room_mask = rooms[i][\"mask\"]\n",
    "        room_type = rooms[i][\"type\"]\n",
    "        room_polygon = mask_to_polygon(room_mask)\n",
    "        if room_polygon == None:\n",
    "            return None\n",
    "        else:\n",
    "            if len(room_polygon) == 0:\n",
    "                return None\n",
    "        room_dict = dict(\n",
    "            polygon=np.concatenate(room_polygon, axis=1).tolist(), \n",
    "            type=room_type)\n",
    "        json_dict[\"rooms\"].append(room_dict)\n",
    "    return json_dict\n",
    "\n",
    "def get_corruption_dataset(rplan_json_corrupt_path):\n",
    "    max_n_polygons = 8\n",
    "    max_n_vertices = 32\n",
    "    names = os.listdir(rplan_json_corrupt_path)\n",
    "    \n",
    "    shifts = []\n",
    "    cors = []\n",
    "    edges = []\n",
    "    vertice_inds = []\n",
    "    polygon_inds = []\n",
    "    graphs = []\n",
    "    areas = []\n",
    "    for name in tqdm(names):\n",
    "        path = os.path.join(rplan_json_corrupt_path, name)\n",
    "        with open(path, \"r\") as f:\n",
    "            json_dict = json.load(f)\n",
    "        \n",
    "        rooms = json_dict[\"rooms\"]\n",
    "        graph = np.array(json_dict[\"graph\"])\n",
    "        n_polygons = len(rooms)\n",
    "        if n_polygons > max_n_polygons:\n",
    "            continue\n",
    "        \n",
    "        local_polygons = [room[\"polygon\"] for room in rooms]\n",
    "        local_polygons = [[np.expand_dims(np.array(v), axis=1) for v in np.array(polygon).T.tolist()] for polygon in local_polygons]\n",
    "        polygon_lens = [len(p) for p in local_polygons]\n",
    "        if max(polygon_lens) > max_n_vertices:\n",
    "            continue\n",
    "        corrupted_polygons = [room[\"cor_polygon\"] for room in rooms]\n",
    "        corrupted_polygons = [[np.expand_dims(np.array(v), axis=1) for v in np.array(polygon).T.tolist()] for polygon in corrupted_polygons]\n",
    "\n",
    "        broadcasted_shifts = []\n",
    "        broadcasted_cors = []\n",
    "        broadcasted_edges = []\n",
    "        broadcasted_vertices = []\n",
    "        broadcasted_polygons = []\n",
    "        broadcasted_graph = []\n",
    "        broadcasted_areas = []\n",
    "        points_counter = 0\n",
    "        for i in range(n_polygons):\n",
    "            cor = np.concatenate([v for v in corrupted_polygons[i]], axis=1).T\n",
    "            polygon = np.concatenate([v for v in local_polygons[i]], axis=1).T\n",
    "            shift = polygon - cor\n",
    "            broadcasted_shifts.append(shift)\n",
    "            broadcasted_cors.append(cor)\n",
    "\n",
    "            local_edges = np.array([[i,(i+1)%len(polygon)] for i in range(len(polygon))])\n",
    "            local_edges += points_counter\n",
    "            broadcasted_edges.append(local_edges)\n",
    "            points_counter += len(polygon)\n",
    "\n",
    "            get_ohe = lambda x, z: np.eye(z)[x]\n",
    "            vertices_ohe = np.concatenate([np.expand_dims(get_ohe(j, max_n_vertices), axis=0) for j in range(len(polygon))], axis=0)\n",
    "            broadcasted_vertices.append(vertices_ohe)\n",
    "\n",
    "            polygon_ohe = np.zeros((len(polygon), max_n_polygons))\n",
    "            polygon_ohe[:, i] = 1\n",
    "            broadcasted_polygons.append(polygon_ohe)\n",
    "\n",
    "            graph_row = graph[i]\n",
    "            b_graph_row = np.repeat(np.expand_dims(graph_row, axis=0), len(polygon), axis=0)\n",
    "            broadcasted_graph.append(b_graph_row)\n",
    "\n",
    "            area = get_polygon_area(local_polygons[i])\n",
    "            b_area = np.ones(len(polygon)) * area\n",
    "            broadcasted_areas.append(b_area)\n",
    "        \n",
    "        broadcasted_shifts = np.concatenate(broadcasted_shifts, axis=0)\n",
    "        broadcasted_cors = np.concatenate(broadcasted_cors, axis=0)\n",
    "        broadcasted_edges = np.concatenate(broadcasted_edges, axis=0)\n",
    "        broadcasted_vertices = np.concatenate(broadcasted_vertices, axis=0)\n",
    "        broadcasted_polygons = np.concatenate(broadcasted_polygons, axis=0)\n",
    "        broadcasted_graph = np.concatenate(broadcasted_graph, axis=0)\n",
    "        broadcasted_areas = np.concatenate(broadcasted_areas, axis=0)\n",
    "\n",
    "        shifts.append(broadcasted_shifts)\n",
    "        cors.append(broadcasted_cors)\n",
    "        edges.append(broadcasted_edges)\n",
    "        vertice_inds.append(broadcasted_vertices)\n",
    "        polygon_inds.append(broadcasted_polygons)\n",
    "        graphs.append(broadcasted_graph)\n",
    "        areas.append(broadcasted_areas)\n",
    "    dataset_dict = dict(\n",
    "        shift=shifts,\n",
    "        corrupt=cors,\n",
    "        edges=edges,\n",
    "        vertice_inds=vertice_inds,\n",
    "        polygon_inds=polygon_inds,\n",
    "        graph=graphs,\n",
    "        area=areas\n",
    "    )\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAEAAQABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiipFgmdQyxOynuFJpfs0//ADwk/wC+DR9mn/54Sf8AfBo+zT/88JP++DR9mn/54Sf98GkNvOoJMMgA5JKmo6KKKKKKKKKKKKKKKKKKKKKKKKK3tO/48Ivx/matUUUVFc/8es3+438q5yiiiiiiiiiiiiiiiiiiiiiiiiitayvbeK0RHkwwzkbT61Y/tG0/56/+On/Cj+0bT/nr/wCOn/Cj+0bT/nr/AOOn/Cj+0bT/AJ6/+On/AAqOe/tnt5FWXLMhAG0+lYtFFFFFFFFFFFFFFFFFFFFPjQPnOeKf5K+po8lfU0eSvqabIgVcjPWtjT9Gt7uxjnkeUM2chSMcEj0qz/wj1p/z0n/76H+FH/CPWn/PSf8A76H+FH/CPWn/AD0n/wC+h/hR/wAI9af89J/++h/hUdzoVrDazSrJMWRCwyRjgfSs7TLGK983zGcbMY2kd8/4Vf8A7Dtv7835j/Cj+w7b+/N+Y/wo/sO2/vzfmP8ACqmo6dDZ26yRs5JcL8xHofasuiiiiiiiiiiiiiiipYf4qlooqOb7g+tdPov/ACCYP+Bf+hGr9FFFV77/AJB9z/1yb+RrE0H/AJeP+A/1rZoorM1z/jyT/roP5GsCiiiiiiiiiiiiiiipYf4qlooqOb7g+tdPov8AyCYP+Bf+hGr9FFFV77/kH3P/AFyb+RrE0H/l4/4D/WtmiiszXP8AjyT/AK6D+RrAoooooooooooooooqWH+KpaKKjm+4PrXT6L/yCYP+Bf8AoRq/RRRVe+/5B9z/ANcm/kaxNB/5eP8AgP8AWtmiiszXP+PJP+ug/kawKKKKKKKKKKKKKKKKlh/iqWiio5vuD610+i/8gmD/AIF/6Eav0UUVXvv+Qfc/9cm/kaxNB/5eP+A/1rZoorM1z/jyT/roP5GsCiiiiiiiiiiiiiiipYf4qlooqOb7g+tdPov/ACCYP+Bf+hGr9FFFV77/AJB9z/1yb+RrE0H/AJeP+A/1rZoorM1z/jyT/roP5GsCiiiiiiiiiiiiiiinxiQ58tWPrgZp+y4/55v/AN80bLj/AJ5v/wB80scd1Mu6KKR1BxlUJFONpesMG2n/AO/Z/wAK6bSUePTIUkRkYbshhgj5jV2iiiq99/yD7n/rk38jXI293Pa7vJfbuxngH+dTf2re/wDPb/xxf8KP7Vvf+e3/AI4v+FH9q3v/AD2/8cX/AAqOe9uLlAk0m5Qc42gc/hVeiiiiiiiiiiiiiiir+m/8tfw/rV+ip/Dv/IPk/wCup/kK16KKKKKr33/IPuf+uTfyNcXRRRRRRRRRRRRRRRRRRRRV/Tf+Wv4f1q/RU/h3/kHyf9dT/IVr0UUUUVXvv+Qfc/8AXJv5GuLooooooooooooooooooooqe2ufs+75N27HfFWP7S/6Zf8Aj3/1qP7S/wCmX/j3/wBapNO1f7BbtF5HmZfdnfjsPb2q3/wkn/Tp/wCRP/rVrWVz9stEn2bN2flznGDirFFFFV77/kH3P/XJv5GuLooooooooooooooooooooqzaKrb9yg9Ooqx5Uf8AcX8qPKj/ALi/lR5Uf9xfyqG6RViBVQDnsK6LRf8AkEwf8C/9CNX6KKKr33/IPuf+uTfyNcXRRRRRRRRRRRRRRRRRRRRVqz/j/CrVFFV7v/VD/erodF/5BMH/AAL/ANCNX6KKKr33/IPuf+uTfyNcXRRRRRRRRRRRRRRRRRRRRVqz/j/CrVFFV7v/AFQ/3q6HRf8AkEwf8C/9CNX6KKKr33/IPuf+uTfyNcXRRRRRRRRRRRRRRRRRRRRVqz/j/CrVFFV7v/VD/erodF/5BMH/AAL/ANCNX6KKKr33/IPuf+uTfyNcXRRRRRRRRRRRRRRRRRRRRVqz/j/CrVFFV7v/AFQ/3q6HRf8AkEwf8C/9CNX6KKKr33/IPuf+uTfyNcXRRRRRRRRRRRRRRRRRRRRVqz/j/CrVFFV7v/VD/erodF/5BMH/AAL/ANCNX6KKKr33/IPuf+uTfyNcXRRRRRRRRRRRRRRRRRRRRVqz/j/CrVFFV7v/AFQ/3q6HRf8AkEwf8C/9CNX6KKKr33/IPuf+uTfyNcXRRRRRRRRRRRRRRRRRRRRVqz/j/CrVFFV7v/VD/erodF/5BMH/AAL/ANCNX6KKKr33/IPuf+uTfyNcXRRRRRRRRRRRRRRRRRRRRSqzL91iPoaXzZP77fnR5sn99vzo82T++350F2YYZiR7mur0X/kEwf8AAv8A0I1foooqvff8g+5/65N/I1xdFFFFFFFFFFFFFFFFFFFFFFFFFdbov/IJg/4F/wChGr9FFFV77/kH3P8A1yb+Rri6KKKKKKKKKKKKKKKKKKKKKKKKKtw6neW8KxRTbUXoNoP9Kk/trUP+fj/xxf8ACj+2tQ/5+P8Axxf8KP7a1D/n4/8AHF/wo/trUP8An4/8cX/Cmvq19JG0bz5VgQRsXkH8KpUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUUV//9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAC9ElEQVR4Ae3cIXNUQRBF4UCh0Gg0Gs3PR6PRaHQ0FVTEVk2aeTV96fdFJW97trvPPdlUJZv39OQDAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAgbEE3p3b7Eul1c9K8U7t+53DE84CMCHFnR0YsENvwlkGTEhxZwcG7NCbcJYBE1Lc2YEBO/QmnL29ARNCtAMCCCDwzwQu+Z3gx1X755eCb6uq149/f/ni6+srjz7/8ehi7drtfwwCUBNmXjUD5mVa24gBNV7zqhkwL9PaRgyo8ZpXzYB5mdY2YkCN17xqBszLtLYRA2q85lUzYF6mtY0YUOM1r5oB8zKtbcSAGq951QyYl2ltIwbUeM2rZsC8TGsbMaDGa141A+ZlWtuIATVe86oZMC/T2kYMqPGaV82AeZnWNrq9AR9qvB5X/303/OOHtq5e8G74Zf/bGwDA0pHhBbc34JIXwc8PLPlV/CehB09x5NLtDQDgiGfBTRgQHM6R0RhwBHNwEwYEh3NkNAYcwRzchAHB4RwZjQFHMAc3YUBwOEdGY8ARzMFNbm/AJTdSelvA9Rspve1596pubwAAewL9/6dvb8Alfxn6tBLh96qg7/HbGwBAn3wZnRmQkUPfFAzoY5/RmQEZOfRNwYA+9hmdGZCRQ98UDOhjn9GZARk59E3BgD72GZ0ZkJFD3xQM6GOf0ZkBGTn0TcGAPvYZnRmQkUPfFAzoY5/RmQEZOfRNwYA+9hmdGZCRQ98UDOhjn9GZARk59E3BgD72GZ0ZkJFD3xQM6GOf0ZkBGTn0TcGAPvYZnRmQkUPfFAzoY5/RmQEZOfRNwYA+9hmdGZCRQ98UDOhjn9H5kvsHBN8eYEnZt8AS0fACBgwPeLkeA5aIhhcwYHjAy/UYsEQ0vIABwwNerseAJaLhBQwYHrD1EEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEbk3gD8wXC07MOJcfAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ind = 13047\n",
    "line = f\"../floorplan_dataset/{ind}.png\"\n",
    "base_img = np.asarray(Image.open(line))\n",
    "img_room_ind = fix_contour_holes(base_img[:,:,2])\n",
    "image_base = Image.fromarray(10*img_room_ind.astype(np.uint8))\n",
    "display(image_base)\n",
    "image_base.save(\"image_base.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAD8UlEQVR4Ae2dsXLTUBBFA0PFh/EJFFSp+QIqClcU1NRUFHwCn0OdmprYkzd2HI2k9XvRXu09aWRL+7S7956VRh4neXO48/55693+3R0CQIC5AoyAOQBcBBkBRsBcAUbAHADuAowAI2CuACNgDgB3AUaAETBXgBEwB4C7ACPACJgrwAiYA8BdgBFwH4F3mwjw/rYs/25bFlrFCITkKhgMAQVNDbW0zUXwVNK3SGFfIsE9sYxAj3oV1kJABRd7eoCAHvUqrIWACi729AABPepVWAsBFVzs6QECetSrsLb3cTjwad/3J71mlpw/BHw4Bs9EXmh/XnSxc/VLRmC1VEUDIaCosavb6r0InhL9WUr36RhwvxR1efzn8c2vyz1Trz9M7YztYwRietWLhoB6nsY6goCYXvWiIaCep7GOICCmV71oCKjnaawjCIjpVS8aAup5GusIAmJ61YuGgHqexjqCgJhe9aIhoJ6nsY4gIKZXvWgIqOdprCMIiOlVLxoC6nka68iegCHfEIlpvip63TfkVp1qPsieAASYB6T+UQio7/F8hxAwr0/9oxBQ3+P5DiFgXp/6R+0JGPIwdPo2/AtYnj3PRH+x5+/xdAO+Df+iqusd9gQgwDUSbu+HXAOmRHt2BZgKENk3RICvE808/prkx4ndoV3RK2fo5E/BXANuUa3SGgio5OYtvdgTMOQucIvyC2tOd1HuAgsqjThsPwIIMAKjPZ8DAvbs3ojaIWCEins+BwTs2b0RtUPACBX3fA4I2LN7I2of8jh8mK7k93n38cH2/vxW6NWrjcAWz/IjdBxCwIhCrs6xmX6vRsBVQ7Jv7QUYMgKfl/z9sRSQd9yeAATIg08jMwRo+JBXBQTkaa+RGQI0fMirAgLytNfIDAEaPuRVAQF52mtkhgANH/KqgIA87TUyQ4CGD3lVQECe9hqZIUDDh7wqICBPe43MEKDhQ14VEJCnvUZmCNDwIa8KCMjTXiMzBGj4kFcFBORpr5EZAjR8yKsCAvK018gMARo+5FUBAXnaa2SGAA0f8qqAgDztNTJDgIYPeVVAQJ72GpkhQMOHvCogIE97jcwQoOFDXhUQkKe9RuYhfz/gsNTLw1JA3nFGIE97jcwQoOFDXhW9F8F1f+9H+J8NMAJ58GlkhgANH/KqgIA87TUyQ4CGD3lVQECe9hqZ7QnofRYI2Pj4z7cEf+wJQABBKjctyZ6AbS6C6z422dT5lsyeAARoKLhuIcDV+dY3BDQlXLcQ4Op86xsCmhKuWwhwdb71DQFNCdctBLg63/qGgKaE6xYCXJ1vfUNAU8J1CwGuzre+IaAp4bqFAFfnW98Q0JRw3doT8B9/FRpuLQGBYgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 13047\n",
    "line = f\"../floorplan_dataset/{ind}.png\"\n",
    "base_img = np.asarray(Image.open(line))\n",
    "img_room_ind = base_img[:,:,1]\n",
    "image_base = Image.fromarray(10*img_room_ind.astype(np.uint8))\n",
    "display(image_base)\n",
    "image_base.save(\"image_base.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4373/1739328955.py:227: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  min_bound = int(edge[left_ind][bound_ind])\n",
      "/tmp/ipykernel_4373/1739328955.py:228: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  max_bound = int(edge[right_ind][bound_ind])\n",
      "/tmp/ipykernel_4373/1739328955.py:245: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  polygon = [(int(p[1]), int(p[0])) for p in polygon]\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAEAAQABAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiilALMFUEknAA71L9juf+feb/vg0fY7n/n3m/74NH2O5/595v8Avg0fY7n/AJ95v++DTJIZYseZG6Z6blIzTKKKKKKKKKKKKKKKKKKKKKKKKKKms/8Aj9g/66L/ADrrKKKKxte/5d/+Bf0rGoooooooooooooooooooooooooqaz/4/YP8Arov866yiiis/U7GW98ry2QbM53E98f4VSj0C7kYqJIchS3LHsM+ntTf7Duf78P5n/Cj+w7n+/D+Z/wAKP7Duf78P5n/CnSaBdxSvG0kOVYqcMe34U3+w7n+/D+Z/wo/sO5/vw/mf8KP7Duf78P5n/Cj+w7n+/D+Z/wAKP7Duf78P5n/CsyiiiiiiiiiiiiiiiprP/j9g/wCui/zrrKKKKKmtf9a3/XN//QDUNFFTXn/H7P8A9dG/nUNFFFFcbRRRRRRRRRRRRRRRU9kC1/bqoJJlUADvyK7H7Hc/8+83/fBo+x3P/PvN/wB8Gj7Hc/8APvN/3waPsdz/AM+83/fBo+x3P/PvN/3wamt7W4WR2aCUARSEkoePkNU6KKmvP+P2f/ro386hoooorjaKKKKKKKKKKKKKKKms/wDj9g/66L/Ousooooqa1/1rf9c3/wDQDUNFFTXn/H7P/wBdG/nUNFFFFcbRRRRRRRRRRRRRRRU1n/x+wf8AXRf511lFFFFOjkaJ96EZwRyAevHepPtUn92H/vyn+FH2qT+7D/35T/Cj7VJ/dh/78p/hS3p3X9wTjJlY8DHc1BRRRRXG0UUUUUUUUUUUUUUVNZ/8fsH/AF0X+ddZRRRRRRRRU15/x+z/APXRv51DRRRRXG0UUUUUUUUUUUUUUVNZ/wDH7B/10X+ddZRRRRRRRRVu5gaS6mdXhKs5IPmr0z9ai+yyf3of+/yf40fZZP70P/f5P8actnMwYgw4UZP75OBnHr7037LJ/eh/7/J/jR9lk/vQ/wDf5P8AGuT/ALKvf+eP/j6/41HPZXFsgeaPapOM7gefwqvRRRRRRRRRRRRRU1n/AMfsH/XRf511lFFFFFFFFFFFTQf6q5/65j/0NahoorM1z/jyT/roP5GsCiiiiiiiiiiiiiprP/j9g/66L/OusoooooooooooqaD/AFVz/wBcx/6GtQ0UVma5/wAeSf8AXQfyNYFFFFFFFFFFFFaGmWMV75vmM42YxtI75/wq/wD2Hbf35vzH+FPj0e3ilSRXlyrBhkjt+FaFFFFTqsK26ySK7FnZflcDGAPY+tJutv8AnjN/39H/AMTRutv+eM3/AH9H/wATRutv+eM3/f0f/E0brb/njN/39H/xNG62/wCeM3/f0f8AxNSTi0iuJY1imwrlRmUdj/u1Hutv+eM3/f0f/E1LG0Bt7nZHIG8sYJkBH319qqUUVma5/wAeSf8AXQfyNYFFFFFFFFFFFFbOg/8ALx/wH+tbNFFFFFTN/wAeUX/XR/5LUNFFFFTXn/H7P/10b+dQ1NB/qrn/AK5j/wBDWoaKKzNc/wCPJP8AroP5GsCiiiiiiiiiiitnQf8Al4/4D/Wtmiiiiipm/wCPKL/ro/8AJahooooqa8/4/Z/+ujfzqGp7cblnTcoLR4G5gM/Mp70n2WT+9D/3+T/Gj7LJ/eh/7/J/jR9lk/vQ/wDf5P8AGsrX4WjsELFCPNA+WRW7H0Nc5RRRRRRRRRRRWzoP/Lx/wH+tbNFFFFFTN/x5Rf8AXR/5LUNFFFFTXn/H7P8A9dG/nUNFFFFZmuf8eSf9dB/I1gUUUUUUUUUUUVs6D/y8f8B/rWzRRRRRUzf8eUX/AF0f+S1DRRRRU15/x+z/APXRv51DRRRRWZrn/Hkn/XQfyNYFFFFFFFFFFFFbOg/8vH/Af61s0UUUUVM3/HlF/wBdH/ktQ0UUUVNef8fs/wD10b+dQ0UUUVma5/x5J/10H8jWBRRRRRRRRRRRWzoP/Lx/wH+tbNFFFFFTN/x5Rf8AXR/5LUNFFFFTXn/H7P8A9dG/nUNFFFFZmuf8eSf9dB/I1gUUUUUUUUUUUVs6D/y8f8B/rWzRRRRRUzf8eUX/AF0f+S1DRRRRU15/x+z/APXRv51DRRRRWZrn/Hkn/XQfyNYFFFFFFFFFFFFbOg/8vH/Af61s0UUUUVaELSWERUoB5rj5pFXsvqaj+yyf3of+/wAn+NH2WT+9D/3+T/Gj7LJ/eh/7/J/jR9lk/vQ/9/k/xo+yyf3of+/yf40t6Nt/cA4yJWHBz3NQUUUUVma5/wAeSf8AXQfyNYFFFFFFFFFFFFbOg/8ALx/wH+tbNFFFFFTN/wAeUX/XR/5LUNFFFFTXn/H7P/10b+dQ0UUUVma5/wAeSf8AXQfyNYFFFFFFFFFFFFbOg/8ALx/wH+tbNFFFFFTN/wAeUX/XR/5LUNFFFFTXn/H7P/10b+dQ0UUUVma5/wAeSf8AXQfyNYFFFFFFFFFFFFPjmliz5cjpnrtYjNP+2XP/AD8Tf99mj7Zc/wDPxN/32aPtlz/z8Tf99mj7Zc/8/E3/AH2aPtlz/wA/E3/fZo+2XP8Az8Tf99mtzR5pZbJvMkd8SHG5iccCtCiiiiuNoooooooooooooooooooooooooqxBe3FshSGTapOcbQefxqT+1b3/AJ7f+OL/AIUf2re/89v/ABxf8KP7Vvf+e3/ji/4Uf2re/wDPb/xxf8KP7Vvf+e3/AI4v+FU6KKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKKK/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAADMUlEQVR4Ae2cbU7DMBBEA+JEPi9n4kz8qlyJeKdrUtedffwhyjof8+a1KlHFcfADAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAAQhAAAIQgAAEIAABCEAAAhCwJfBxUbL2yHl+Hlm0eM3n4uttdzkAbFfJ4hvCgMXAt7scBmxXyeIbwoDFwLe7HAZsV8niG8KAxcC3u9zSvwZ7+jb8w3A86Uffbw1PdL8o2OYlEMApMcKAEjUHITEggFNihAElag5CYkAAp8QIA0rUHITEgABOiREGlKg5CFnegK8ATmbUMouPI/vcJ3f2zOqrAPz3yVTmni9dW/4lAIBLfXrDk2HAG5Z26S1jwKU43/Bk5Q246oNQtvs2OmD1Z8QXAdjng2P5lwAARq/FKvsxoErTo5wYMCJTZT8GVGl6lBMDRmSq7MeAKk2PcmLAiEyV/RhQpelRTgwYkamy/0XPBAO8LZqJZ4lifHbm7QDEGeLpWUC1j/cARch9jgHuDat8GKAIuc8xwL1hlQ8DFCH3OQa4N6zyYYAi5D7HAPeGVT4MUITc5+UNmHom2Oa0SB12+o3R051zN3M7agrA7eDs79QjzdTi7J309eVfAgDoMtTcwoCavffUGNBZ1NzCgJq999QY0FnU3MKAmr331BjQWdTcwoCavffUS58I9cvObrX4wImnSO8FYCJgTOw4eA9QhNznGODesMqHAYqQ+xwD3BtW+TBAEXKfY4B7wyofBihC7nMMcG9Y5cMARch9jgHuDat8GKAIuc8xwL1hlQ8DFCH3OQa4N6zyYYAi5D7HAPeGVT4MUITc5xjg3rDKhwGKkPscA9wbVvkwQBFyn2OAe8MqHwYoQu7zlV+XbxmYT/hvGaeXXwng5wlf9z8NldnJe0CGluNaDHBsNZMJAzK0HNdigGOrmUwYkKHluBYDHFvNZMKADC3HtRjg2Gom08oHIpn7Or5Tq+cXTwHY8cnOLALeA2bJuRyHAS5NzubAgFlyLsdhgEuT5IAABCAAAQhAAAIQgAAEIAABCEAAAhCAAAQgAAEIQAACEIAABCAAAQhAAAIQgAAEIAABCPwl8AtBYBcj++SfRgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rooms = get_rooms_without_spans(base_img)\n",
    "flat_mask = np.zeros((256, 256))\n",
    "for room in rooms:\n",
    "    flat_mask += room[\"mask\"]\n",
    "image = Image.fromarray(50*flat_mask.astype(np.uint8))\n",
    "display(image)\n",
    "image.save(f\"image_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4141/2168127290.py:245: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  polygon = [(int(p[1]), int(p[0])) for p in polygon]\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAC8UlEQVR4Ae3bS1IjMRBFUZroFdWaelmsiTUxYKRwRwiLSmemdJjJhfJz38UDMG9vvhBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBDYlsCfV2x2Pd/k8/krazfe167tcwuAfbJc24QBa9z2ucWAfbJc24QBa9z2ucWAfbJc24QBa9z2ucWAfbJc24QBa9z2ucWAfbJc2+SW3wlek97/nv4N3/UxKfn9+Om6j1X/Pr50/yufNwx6/1TfFb0HRJHtUpcBXZKKmpMBUWS71GVAl6Si5mRAFNkudRnQJamoORkQRbZLXQZ0SSpqTgZEke1SlwFdkoqakwFRZLvUZUCXpKLmZEAU2S51GdAlqag5GRBFtktdBnRJKmpOBkSR7VKXAV2SipqTAVFku9RlQJekouZkQBTZLnUZ0CWpqDlv+bD09TjdVfjz0cO0UR+X/y2Al/HzHjD4cOCBAQeGPqzMgAHHgQcGHBj6sDIDBhwHHhhwYOjDygwYcBx4YMCBoQ8rM2DAceCBAQeGPqzMgAHHgQcGHBj6sDIDBhwHHhhwYOjDygwYcBx4CPt8wMDyZX/sHrr+6HALgP/sN7x0/WiUnG/yHpDDvU5XBtTJImcSBuRwr9OVAXWyyJmEATnc63RlQJ0sciZhQA73Ol0ZUCeLnEkYkMO9TlcG1MkiZxIG5HCv05UBdbLImYQBOdzrdGVAnSxyJmFADvc6XRlQJ4ucSRiQw71OVwbUySJnEgbkcK/TlQF1ssiZhAE53Ot0ZUCdLHImYUAO9zpdGVAni5xJGJDDvU5XBtTJImcSBuRwr9OVAXWyyJmEATnc63RlQJ0sciZhQA73Ol2j/n2+zoaTSfwITABt/5gB20c8WZABE0DbP2bA9hFPFmTABND2jxmwfcSTBRkwAbT9YwZsH7EFEUAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEEEAAAQQQQAABBBBAAAEEDibwBenTDgqrCoRmAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_ind = 13047\n",
    "json_path = \"/home/evgmaslov/Files/rplan_json\"\n",
    "names = [name for name in os.listdir(json_path) if name.startswith(f\"{image_ind}\")]\n",
    "if len(names) != 0:\n",
    "    name = names[0]\n",
    "    path = os.path.join(json_path, name)\n",
    "    with open(path, \"r\") as f:\n",
    "        json_dict = json.load(f)\n",
    "    flat_mask = np.zeros((256, 256))\n",
    "    rooms = []\n",
    "    for polygon in [r[\"polygon\"] for r in json_dict[\"rooms\"]]:\n",
    "        polygon = [np.expand_dims(np.array(v), axis=1) for v in np.array(polygon).T.tolist()]\n",
    "        mask = polygon_to_mask(polygon)\n",
    "        rooms.append(mask)\n",
    "        flat_mask += mask\n",
    "    flat_mask = flat_mask*50\n",
    "    image = Image.fromarray(flat_mask.astype(np.uint8))\n",
    "    display(image)\n",
    "    image.save(f\"image_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53266/1901397484.py:245: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  polygon = [(int(p[1]), int(p[0])) for p in polygon]\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAACp0lEQVR4Ae3dQU7DMBAF0II4Ue5/Bs7Ehkg4ilFa2xD7PzbFLnE9b36itlnwePghQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBCYW+Cty/a3wyrb52Hi+vD1I6+/xs+/fP85SPw9HuBjyq4fT7m9iBfOn/gEANjTk/ooAamd3+uWgF0i9VECUju/1323d4LbvrHy8eKnq/3oJ94ROgVK6byRBOT1vKxYAkqPvJEE5PW8rFgCSo+8kQTk9bysWAJKj7yRBOT1vKxYAkqPvJEE5PW8rFgCSo+8UXwCnrovsNUCcnzi4tf4teX+cv4pgOrGnrgRUV3jn56IPwUA/FPybvOyfa4B/co5Xk6/Vx53Vb0bwOdfX09dA/qld86VJGDOvvXbtQT0s5xzJQmYs2/9di0B/SznXEkC5uxbv11LQD/LOVe628fhx3bqGPR9wGn9AyddAwbiTrG0BEzRpoGblICBuFMsLQFTtGngJiVgIO4US0vAFG0auMn4BNzm4/Dvd4V/f7YlIPEJANASnxWOlYAVuthSgwS06K1wrASs0MWWGiSgRW+FYyVghS621CABLXorHCsBK3SxpQYJaNFb4VgJWKGLLTVIQIveCsfGJ6Dxxsh2HoKz6XH3Ns73cHG28V9snFVaeeWbAsSfAgAqgY2ZloCYVlcKlYAKTMy0BMS0ulKoBFRgYqYlIKbVlUIloAITMy0BMa2uFCoBFZiYaQmIaXWlUAmowMRMS0BMqxVKgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIEFhV4At4TxENsnqklgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEACAAAAAB5Gfe6AAAC5UlEQVR4Ae3dUXLbIBQFUDXTFWn/a8ia2pnaTjDGIxFQgXfyEwtLiHfelRy5H902PwQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAnML/Oqy/L1+1s/6Q6uO/Kg6aqGDACzUzKpSJKCKbaGDJGChZlaVIgFVbAsdJAELNbOqlPAJ+F3F1u+gvTB1t2ek8AkAUIhcmGEJCNPqQqESUIAJMywBYVpdKFQCCjBhhiUgTKsLhUpAASbMsASEaXWhUAkowIQZloAwrS4UKgEFmDDDp/5dYD/Ksnf7Gv/oCg7v5xI4TLXojhKwaGMPl3XqJnh41n87lu6Z7+6QNcecXFa6e0+A9EzHtj7f6Ryb4txe7gHnvNbbWwLW6+m5iiTgnNd6e0vAej09V1HTP4T2+7kfL+4Dye/7u19/89xHtu326uut5MgOGx8d5pxqSgBTtavDYiWgA+pUUzb9FGhR+e1j4Hmqbh8LowHcCu1W7zPs5h6QkQQbkIBgDc/KlYCMJNiABARreFauBGQkwQYkIFjDs3LDJ2CYp8H0+S/dytrWcCB8AgA0TNOUU0nAlG1ruGgJaIg55VQSMGXbGi5aAhpiTjmVBEzZtoaLloCGmFNOFT4BY3wh8vf7j+u+AkmDGj4BANJAxNv64T1gT8QeW48X397+Xxf5tyW8eukSeKUSaUwCInX7Va0//C820rtduvV0uvwmmI88HXLFpkvgCuWRzyEBI3fnirVJwBXKI59DAkbuzhVrk4ArlEc+hwSM3J0r1tb0Yejtgod49MlX6BLITWKNSECsfufVSkBuEmtEAmL1O69WAnKTWCMSEKvfqiVAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQILCjwBxkMFKihHV7WAAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=256x256>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, [1, 0]], [1, [6, 3]], [1, [5, 2]]]\n"
     ]
    }
   ],
   "source": [
    "eval_ind = 6\n",
    "rplan_json_corrupt_path = \"/home/evgmaslov/Files/rplan_json_corrupt\"\n",
    "names = os.listdir(rplan_json_corrupt_path)\n",
    "eval_path = os.path.join(rplan_json_corrupt_path, names[eval_ind])\n",
    "with open(eval_path, \"r\") as f:\n",
    "    json_dict = json.load(f)\n",
    "rooms = json_dict[\"rooms\"]\n",
    "\n",
    "polygons = [[np.expand_dims(np.array(v), axis=1) for v in np.array(room[\"polygon\"]).T.tolist()] for room in rooms]\n",
    "flat_mask = np.zeros((256, 256))\n",
    "for p in polygons:\n",
    "    mask = polygon_to_mask(p)\n",
    "    flat_mask[*np.where(mask == 1)] += 1\n",
    "flat_img = Image.fromarray(50*flat_mask.astype(np.uint8))\n",
    "display(flat_img)\n",
    "\n",
    "cor_polygons = [[np.expand_dims(np.array(v), axis=1) for v in np.array(room[\"cor_polygon\"]).T.tolist()] for room in rooms]\n",
    "cor_flat_mask = np.zeros((256, 256))\n",
    "for p in cor_polygons:\n",
    "    mask = polygon_to_mask(p)\n",
    "    cor_flat_mask[*np.where(mask == 1)] += 1\n",
    "cor_flat_img = Image.fromarray(50*cor_flat_mask.astype(np.uint8))\n",
    "display(cor_flat_img)\n",
    "\n",
    "print(json_dict[\"cor_sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/evgmaslov/Expansion/Work/AIRI/computational_intelligence/house_diffusion/house_diffusion_refactored/sandbox\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from script_utils import add_dict_to_argparser\n",
    "from diffusion_utils import diffusion_defaults, GaussianDiffusion\n",
    "from model_utils import model_defaults, HouseTransformerModel, DiffusionModel, CorruptDiffusionModel\n",
    "from train_utils import train_defaults, ImageCallback\n",
    "from data_utils import get_rplan_dataset, get_corruption_dataset, corruption_collator\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949f7f2034b74f1aaeb7da9af7659156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78242 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_json_folder = \"/home/evgmaslov/Files/rplan_json_corrupt\"\n",
    "task_type = \"corrupt_correction\"\n",
    "loss_type = \"MSE\"\n",
    "test_size=0.1\n",
    "random_seed=42\n",
    "\n",
    "model = HouseTransformerModel(**model_defaults())\n",
    "diffusion = GaussianDiffusion(**diffusion_defaults())\n",
    "model.to(\"cuda\")\n",
    "diffusion_model = CorruptDiffusionModel(model, diffusion, loss_type)\n",
    "\n",
    "dataset = get_rplan_dataset(dataset_json_folder, model.analog_bit) if task_type == \"floorplan_generation\" else get_corruption_dataset(dataset_json_folder)\n",
    "dataset = dataset.train_test_split(test_size=test_size, seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b9bd4d792d437690d851da9ef9d3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70417 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "DiffusionModel.forward() got an unexpected keyword argument 'shift'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m     wandb_callback \u001b[38;5;241m=\u001b[39m ImageCallback(trainer, dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m], num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     35\u001b[0m     trainer\u001b[38;5;241m.\u001b[39madd_callback(wandb_callback)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Files/py_venvs/housediffusion/lib/python3.12/site-packages/transformers/trainer.py:2164\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Files/py_venvs/housediffusion/lib/python3.12/site-packages/transformers/trainer.py:2522\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2516\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2517\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2520\u001b[0m )\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2522\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2525\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2528\u001b[0m ):\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2530\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/Files/py_venvs/housediffusion/lib/python3.12/site-packages/transformers/trainer.py:3655\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3653\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   3654\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3655\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3657\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3661\u001b[0m ):\n",
      "File \u001b[0;32m~/Files/py_venvs/housediffusion/lib/python3.12/site-packages/transformers/trainer.py:3709\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3707\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3708\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3709\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3710\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3711\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Files/py_venvs/housediffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Files/py_venvs/housediffusion/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: DiffusionModel.forward() got an unexpected keyword argument 'shift'"
     ]
    }
   ],
   "source": [
    "lr=1e-4\n",
    "weight_decay=0.0\n",
    "batch_size=1\n",
    "n_epochs=1\n",
    "output_dir=\"/media/evgmaslov/Expansion/Work/AIRI/computational_intelligence/house_diffusion/house_diffusion_refactored/checkpoints\"\n",
    "save_steps=100\n",
    "eval_strategy=\"steps\"\n",
    "eval_steps=100\n",
    "push_to_hub=False\n",
    "hub_strategy=\"checkpoint\"\n",
    "\n",
    "training_params = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=n_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    save_steps=save_steps, \n",
    "    learning_rate=lr, weight_decay=weight_decay,\n",
    "    fp16=False, bf16=False,\n",
    "    report_to=\"wandb\",\n",
    "    save_total_limit=2,\n",
    "    eval_strategy=eval_strategy,\n",
    "    eval_steps=eval_steps,\n",
    "    push_to_hub=push_to_hub,\n",
    "    hub_strategy=hub_strategy,\n",
    "    remove_unused_columns=False)\n",
    "trainer = Trainer(\n",
    "    model=diffusion_model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=corruption_collator,\n",
    "    args=training_params)\n",
    "if task_type == \"corrupt_correction\":\n",
    "    wandb_callback = ImageCallback(trainer, dataset[\"test\"], num_samples=2)\n",
    "    trainer.add_callback(wandb_callback)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "housediffusion",
   "language": "python",
   "name": "housediffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
